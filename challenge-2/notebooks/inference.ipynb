{
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        },
        "kaggle": {
            "accelerator": "nvidiaTeslaT4",
            "dataSources": [
                {
                    "sourceId": 102966,
                    "databundleVersionId": 12412856,
                    "sourceType": "competition"
                }
            ],
            "dockerImageVersionId": 31041,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook",
            "isGpuEnabled": true
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "```\nAuthor: Annam.ai IIT Ropar\nTeam Name: RAV\nTeam Members: VIGNESH J, ASHWATH VINODKUMAR, RAHUL BHARGAV TALLADA\nLeaderboard Rank: 13\n```\n\n# This is the notebook used for soil classification challenge (Task 2)."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Setup and Configuration\n\nInstalling required packages and importing necessary libraries for the soil classification task."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "trusted": true
            },
            "outputs": [],
            "source": "!pip install open-clip-torch pandas pillow scikit-learn --quiet\n\nimport sys\nimport os\nsys.path.append('../src')\n\nimport open_clip\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Import custom utilities (if available)\ntry:\n    from preprocessing import load_and_preprocess_image, normalize_embeddings\n    from postprocessing import save_predictions, analyze_predictions\n    print(\"Successfully imported custom utilities\")\nexcept ImportError:\n    print(\"Custom utilities not found, using internal functions\")\n\n# Configuration\nMODEL_NAME = \"ViT-H-14\"\nPRETRAINED = \"laion2b_s32b_b79k\"\nBATCH_SIZE = 8\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load model and preprocessor\nmodel, _, preprocess = open_clip.create_model_and_transforms(\n    model_name=MODEL_NAME,\n    pretrained=PRETRAINED\n)\nmodel = model.to(DEVICE).eval()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Data Loading\n\nLoading the training and test datasets for the soil classification task."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# Load metadata\nDATA_DIR = Path(\"../data\")\nif not DATA_DIR.exists():\n    # For Kaggle environment\n    DATA_DIR = Path(\"/kaggle/input/soil-classification-part-2/soil_competition-2025\")\n\ntrain_df = pd.read_csv(DATA_DIR / \"train_labels.csv\" if DATA_DIR.exists() else \"/kaggle/input/soil-classification-part-2/soil_competition-2025/train_labels.csv\")\ntest_df = pd.read_csv(DATA_DIR / \"test_ids.csv\" if DATA_DIR.exists() else \"/kaggle/input/soil-classification-part-2/soil_competition-2025/test_ids.csv\")\n\nprint(f\"Training samples: {len(train_df)}\")\nprint(f\"Test samples: {len(test_df)}\")\n\n# Display sample data\ndisplay(train_df.head())\ndisplay(test_df.head())"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Text Prompts for Zero-Shot Classification\n\nDefining text prompts for soil and non-soil categories to use with CLIP model."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# Binary classification prompts\nsoil_prompts = [\n    \"A photograph of soil, earth, dirt, or ground surface\",\n    \"Agricultural soil in a field or garden\",\n    \"Natural earth surface with visible soil texture\",\n    \"Close-up view of soil, dirt, or earth material\",\n    \"Ground surface showing soil composition\",\n    \"Farmland soil or agricultural earth\",\n    \"Natural soil formation with organic matter\"\n]\n\nnon_soil_prompts = [\n    \"A photograph with no soil, dirt, or earth visible\",\n    \"Indoor scene without any ground or soil\",\n    \"Water, sky, buildings, or other non-soil objects\",\n    \"Concrete, asphalt, or artificial surfaces\",\n    \"Plants, rocks, or objects without visible soil\",\n    \"Urban environment without natural earth\",\n    \"Clean surfaces without dirt or soil material\"\n]\n\n# Precompute text embeddings for binary classification\nwith torch.no_grad():\n    # Soil embeddings\n    soil_embeddings = []\n    for prompt in soil_prompts:\n        text = open_clip.tokenize([prompt]).to(DEVICE)\n        soil_embeddings.append(model.encode_text(text))\n    soil_text_embedding = torch.mean(torch.cat(soil_embeddings), dim=0, keepdim=True)\n    \n    # Non-soil embeddings\n    non_soil_embeddings = []\n    for prompt in non_soil_prompts:\n        text = open_clip.tokenize([prompt]).to(DEVICE)\n        non_soil_embeddings.append(model.encode_text(text))\n    non_soil_text_embedding = torch.mean(torch.cat(non_soil_embeddings), dim=0, keepdim=True)\n    \n    # Normalize embeddings for cosine similarity\n    soil_text_embedding = soil_text_embedding / soil_text_embedding.norm(dim=-1, keepdim=True)\n    non_soil_text_embedding = non_soil_text_embedding / non_soil_text_embedding.norm(dim=-1, keepdim=True)\n\nprint(f\"Created text embeddings for {len(soil_prompts)} soil prompts and {len(non_soil_prompts)} non-soil prompts\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Image Embedding Functions\n\nCreating functions to extract image embeddings in a memory-efficient way."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# Memory-optimized embedding generator\ndef get_image_embeddings(image_paths):\n    \"\"\"Batch processing to prevent OOM errors\"\"\"\n    embeddings = []\n    for i in range(0, len(image_paths), BATCH_SIZE):\n        batch_paths = image_paths[i:i+BATCH_SIZE]\n        batch = torch.stack([preprocess(Image.open(p).convert(\"RGB\")) for p in batch_paths])\n        \n        with torch.no_grad():\n            batch = batch.to(DEVICE)\n            batch_emb = model.encode_image(batch)\n            embeddings.append(batch_emb.cpu().numpy())\n        \n        # Memory cleanup\n        del batch, batch_emb\n        torch.cuda.empty_cache()\n    \n    return np.concatenate(embeddings)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Training Data Preparation\n\nPreparing the training data for the soil classification model."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# Prepare training data - since all training images contain soil, label them as 1\ntrain_images = [DATA_DIR / \"train\" / img_id if DATA_DIR.exists() else Path(\"/kaggle/input/soil-classification-part-2/soil_competition-2025/train\")/img_id \n               for img_id in train_df.image_id]\nX_train = get_image_embeddings(train_images)\n\n# All training images are soil (label = 1)\n# For a more robust classifier, you might want to add negative examples (non-soil images)\ny_train = np.ones(len(X_train), dtype=int)  # All are soil = 1\n\nprint(f\"Training samples: {len(X_train)} (all labeled as soil=1)\")\n\n# Note: Since we only have positive examples, we'll rely more on zero-shot classification\n# Train a simple classifier anyway (though it may not be very effective with only positive examples)\nif len(np.unique(y_train)) > 1:  # Only train if we have both classes\n    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n        X_train, y_train, test_size=0.2, random_state=42\n    )\n    \n    clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n    clf.fit(X_train_split, y_train_split)\n    val_acc = clf.score(X_val_split, y_val_split)\n    print(f\"Validation Accuracy: {val_acc:.2%}\")\nelse:\n    print(\"Only one class in training data - using pure zero-shot classification\")\n    clf = None"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Prediction Functions\n\nImplementing functions to predict whether an image contains soil or not."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# Binary prediction function\ndef predict_is_soil(image_path, threshold=0.0):\n    \"\"\"\n    Predict if image contains soil (1) or not (0)\n    Uses zero-shot CLIP classification\n    \"\"\"\n    image = preprocess(Image.open(image_path).convert(\"RGB\")).unsqueeze(0).to(DEVICE)\n    \n    with torch.no_grad():\n        # Get image features\n        image_features = model.encode_image(image)\n        image_features /= image_features.norm(dim=-1, keepdim=True)\n        \n        # Get text features\n        soil_features = soil_text_embedding.to(DEVICE)\n        non_soil_features = non_soil_text_embedding.to(DEVICE)\n        \n        # Calculate similarities\n        soil_similarity = (image_features @ soil_features.T).item()\n        non_soil_similarity = (image_features @ non_soil_features.T).item()\n        \n        # Use softmax to get probabilities\n        logits = torch.tensor([non_soil_similarity, soil_similarity])\n        probs = torch.softmax(logits, dim=0)\n        \n        # Return 1 if soil probability > non-soil probability + threshold\n        is_soil = 1 if probs[1] > (probs[0] + threshold) else 0\n        \n    return is_soil, probs[1].item()  # Return prediction and soil probability\n\n# Alternative simpler approach - just compare similarities\ndef predict_is_soil_simple(image_path):\n    \"\"\"Simpler version - just compare soil vs non-soil similarity\"\"\"\n    image = preprocess(Image.open(image_path).convert(\"RGB\")).unsqueeze(0).to(DEVICE)\n    \n    with torch.no_grad():\n        image_features = model.encode_image(image)\n        image_features /= image_features.norm(dim=-1, keepdim=True)\n        \n        soil_features = soil_text_embedding.to(DEVICE)\n        non_soil_features = non_soil_text_embedding.to(DEVICE)\n        \n        soil_sim = (image_features @ soil_features.T).item()\n        non_soil_sim = (image_features @ non_soil_features.T).item()\n        \n        # Return 1 if more similar to soil than non-soil\n        return 1 if soil_sim > non_soil_sim else 0"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Testing on Training Images\n\nVerifying the prediction functions on a few training images."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# Test on a few training images to verify\nprint(\"\\nTesting on a few training images (should all be 1 since they contain soil):\")\nsample_images = train_images[:5]\nfor i, img_path in enumerate(sample_images):\n    prediction, confidence = predict_is_soil(img_path)\n    simple_pred = predict_is_soil_simple(img_path)\n    print(f\"Image {i+1}: Advanced={prediction} (conf={confidence:.3f}), Simple={simple_pred}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Generating Predictions for Test Set\n\nApplying the model to the test dataset and generating predictions."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# Generate predictions for test set\nprint(f\"\\nGenerating predictions for {len(test_df)} test images...\")\ntest_images = [DATA_DIR / \"test\" / img_id if DATA_DIR.exists() else Path(\"/kaggle/input/soil-classification-part-2/soil_competition-2025/test\")/img_id \n              for img_id in test_df.image_id]\n\n# Use the simple approach for final predictions\npredictions = []\nfor img_path in test_images:\n    pred = predict_is_soil_simple(img_path)\n    predictions.append(pred)\n\ntest_df[\"is_soil\"] = predictions"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Saving Results and Analysis\n\nSaving the predictions to a CSV file and analyzing the distribution of predictions."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# Save results\noutput_file = \"binary_soil_submission.csv\"\ntest_df[[\"image_id\", \"is_soil\"]].to_csv(output_file, index=False)\n\n# Analyze prediction distribution\nprint(f\"\\nPrediction distribution:\")\nprint(f\"Soil (1): {sum(predictions)} images\")\nprint(f\"Non-soil (0): {len(predictions) - sum(predictions)} images\")\nprint(f\"Percentage classified as soil: {sum(predictions)/len(predictions)*100:.1f}%\")\n\nprint(f\"\\nBinary classification complete! Results saved to '{output_file}'\")\n\n# Display sample predictions\ndisplay(test_df.head(10))"
        }
    ]
}

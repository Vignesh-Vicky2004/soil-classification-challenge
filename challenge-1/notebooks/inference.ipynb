{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "Team Name: RAV\n",
    "Team Members: VIGNESH J, ASHWATH VINODKUMAR, RAHUL BHARGAV TALLADA\n",
    "Leaderboard Rank: 50\n",
    "```\n",
    "\n",
    "# Soil Classification Challenge - Inference Notebook\n",
    "\n",
    "This notebook contains the inference pipeline for the soil classification challenge. It loads the trained model and makes predictions on test images using a hybrid approach combining zero-shot CLIP features and a trained logistic regression classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "First, we'll install the required packages and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install open-clip-torch pandas pillow scikit-learn --quiet\n",
    "\n",
    "import open_clip\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Define the model configuration and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configuration (MODIFY IF NEEDED)\n",
    "MODEL_NAME = \"ViT-H-14\"        # High-performance vision transformer\n",
    "PRETRAINED = \"laion2b_s32b_b79k\"  # Pretraining dataset\n",
    "BATCH_SIZE = 8                 # Reduce to 4 if OOM errors persist\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CLASSES = [\"Alluvial soil\", \"Black Soil\", \"Clay soil\", \"Red soil\"]\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Loading\n",
    "\n",
    "Load the pre-trained CLIP model and preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load model and preprocessor\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    model_name=MODEL_NAME,\n",
    "    pretrained=PRETRAINED\n",
    ")\n",
    "model = model.to(DEVICE).eval()\n",
    "print(f\"Loaded {MODEL_NAME} model with {PRETRAINED} weights\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Trained Model and Embeddings\n",
    "\n",
    "Load the classifier and text embeddings saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load classifier\n",
    "with open('../models/classifier.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "    \n",
    "# Load text embeddings\n",
    "text_embeddings = torch.load('../models/text_embeddings.pt')\n",
    "\n",
    "print(\"Loaded trained classifier and text embeddings\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Test Data\n",
    "\n",
    "Load the test data for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load test data\n",
    "# Update paths as needed for your environment\n",
    "test_df = pd.read_csv(\"/kaggle/input/soil-classification/soil_classification-2025/test_ids.csv\")\n",
    "print(f\"Loaded {len(test_df)} test samples\")\n",
    "print(test_df.head())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Image Embedding Function\n",
    "\n",
    "Define a memory-optimized function to generate image embeddings in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Memory-optimized embedding generator\n",
    "def get_image_embeddings(image_paths):\n",
    "    \"\"\"Batch processing to prevent OOM errors\"\"\"\n",
    "    embeddings = []\n",
    "    for i in range(0, len(image_paths), BATCH_SIZE):\n",
    "        batch_paths = image_paths[i:i+BATCH_SIZE]\n",
    "        batch = torch.stack([preprocess(Image.open(p).convert(\"RGB\")) for p in batch_paths])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch = batch.to(DEVICE)\n",
    "            batch_emb = model.encode_image(batch)\n",
    "            embeddings.append(batch_emb.cpu().numpy())\n",
    "        \n",
    "        # Explicit memory cleanup\n",
    "        del batch, batch_emb\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return np.concatenate(embeddings)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hybrid Prediction Function\n",
    "\n",
    "Define a function that combines logistic regression predictions with zero-shot CLIP predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Hybrid prediction function\n",
    "def predict_image(image_path):\n",
    "    img_emb = get_image_embeddings([image_path])\n",
    "    probe_pred = clf.predict_proba(img_emb)\n",
    "    \n",
    "    image = preprocess(Image.open(image_path).convert(\"RGB\")).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        zero_shot_probs = []\n",
    "        for cls in CLASSES:\n",
    "            text_features = text_embeddings[cls].to(DEVICE)\n",
    "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "            zero_shot_probs.append((image_features @ text_features.T).item())\n",
    "        zero_shot_probs = torch.softmax(torch.tensor(zero_shot_probs), dim=0).numpy()\n",
    "    \n",
    "    # Weighted ensemble (70% logistic regression, 30% zero-shot)\n",
    "    combined_probs = 0.7*probe_pred + 0.3*zero_shot_probs\n",
    "    return CLASSES[np.argmax(combined_probs)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Predictions\n",
    "\n",
    "Make predictions on the test set and create a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate predictions\n",
    "# Update paths as needed for your environment\n",
    "test_images = [Path(\"/kaggle/input/soil-classification/soil_classification-2025/test\")/img_id for img_id in test_df.image_id]\n",
    "print(f\"Generating predictions for {len(test_images)} test images...\")\n",
    "\n",
    "# Process images in batches and show progress\n",
    "predictions = []\n",
    "for i, img_path in enumerate(test_images):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processing image {i+1}/{len(test_images)}\")\n",
    "    predictions.append(predict_image(img_path))\n",
    "\n",
    "test_df[\"soil_type\"] = predictions"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Submission File\n",
    "\n",
    "Save the predictions to a CSV file for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save submission file\n",
    "submission_path = \"submission.csv\"\n",
    "test_df.to_csv(submission_path, index=False)\n",
    "print(f\"Submission file saved to {submission_path}\")\n",
    "print(f\"Prediction distribution:\\n{test_df['soil_type'].value_counts()}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Inference Summary\n",
    "\n",
    "Summarize the inference process and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Inference Summary:\")\n",
    "print(f\"- Model: {MODEL_NAME} with {PRETRAINED} weights\")\n",
    "print(f\"- Test samples: {len(test_df)}\")\n",
    "print(f\"- Prediction approach: Hybrid (70% logistic regression, 30% zero-shot CLIP)\")\n",
    "print(f\"- Classes: {CLASSES}\")\n",
    "print(f\"- Submission file: {submission_path}\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

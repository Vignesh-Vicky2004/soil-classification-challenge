{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Team Name: RAV\n",
    "Team Members: VIGNESH J, ASHWATH VINODKUMAR, RAHUL BHARGAV TALLADA\n",
    "Leaderboard Rank: 50\n",
    "```\n",
    "\n",
    "# Soil Classification Challenge - Inference Notebook\n",
    "\n",
    "This notebook contains the inference pipeline for the soil classification challenge. It uses a hybrid approach combining logistic regression and zero-shot classification to predict soil types from images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "First, we'll install the required packages and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "source": [
    "!pip install open-clip-torch pandas pillow scikit-learn --quiet\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import open_clip\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import custom utilities\n",
    "try:\n",
    "    from preprocessing import get_image_embeddings, generate_text_embeddings\n",
    "    from postprocessing import predict_image, batch_predict, create_submission\n",
    "    print(\"Successfully imported custom utilities\")\n",
    "except ImportError:\n",
    "    print(\"Custom utilities not found, using internal functions\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Define the model configuration and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Configuration (MODIFY IF NEEDED)\n",
    "MODEL_NAME = \"ViT-H-14\"        # High-performance vision transformer\n",
    "PRETRAINED = \"laion2b_s32b_b79k\"  # Pretraining dataset\n",
    "BATCH_SIZE = 8                 # Reduce to 4 if OOM errors persist\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CLASSES = [\"Alluvial soil\", \"Black Soil\", \"Clay soil\", \"Red soil\"]\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Loading\n",
    "\n",
    "Load the pre-trained CLIP model and preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Load model and preprocessor\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    model_name=MODEL_NAME,\n",
    "    pretrained=PRETRAINED\n",
    ")\n",
    "model = model.to(DEVICE).eval()\n",
    "print(f\"Loaded {MODEL_NAME} model with {PRETRAINED} weights\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading\n",
    "\n",
    "Load the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Load metadata\n",
    "DATA_DIR = Path(\"../data\")\n",
    "if not DATA_DIR.exists():\n",
    "    # For Kaggle environment\n",
    "    DATA_DIR = Path(\"/kaggle/input/soil-classification/soil_classification-2025\")\n",
    "\n",
    "train_df = pd.read_csv(DATA_DIR / \"train_labels.csv\" if DATA_DIR.exists() else \"/kaggle/input/soil-classification/soil_classification-2025/train_labels.csv\")\n",
    "test_df = pd.read_csv(DATA_DIR / \"test_ids.csv\" if DATA_DIR.exists() else \"/kaggle/input/soil-classification/soil_classification-2025/test_ids.csv\")\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nTraining data sample:\")\n",
    "display(train_df.head())\n",
    "print(\"\\nTest data sample:\")\n",
    "display(test_df.head())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prompt Engineering\n",
    "\n",
    "Create rich text prompts for each soil class to enhance zero-shot classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Enhanced prompt engineering\n",
    "class_prompts = {\n",
    "    \"Alluvial soil\": [\n",
    "        \"A high-resolution photo of alluvial soil: light brown, fine-textured, river-deposited\",\n",
    "        \"Satellite image showing alluvial plains with fertile soil\",\n",
    "        \"Microscopic view of alluvial soil particles\"\n",
    "    ],\n",
    "    \"Black Soil\": [\n",
    "        \"Agricultural black soil with high clay content\",\n",
    "        \"Vertisol soil cracking in dry conditions\",\n",
    "        \"Aerial view of black cotton soil fields\"\n",
    "    ],\n",
    "    \"Clay soil\": [\n",
    "        \"Sticky clay soil with poor drainage\",\n",
    "        \"Cracked clay surface during drought\",\n",
    "        \"Red clay soil with high iron content\"\n",
    "    ],\n",
    "    \"Red soil\": [\n",
    "        \"Lateritic red soil in tropical regions\",\n",
    "        \"Red earth with visible iron oxide deposits\",\n",
    "        \"Terra rossa soil in Mediterranean climate\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"Created prompts for {len(class_prompts)} soil classes\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Text Embedding Generation\n",
    "\n",
    "Precompute text embeddings for each class prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Precompute text embeddings\n",
    "# Use utility function if available, otherwise use inline code\n",
    "try:\n",
    "    text_embeddings = generate_text_embeddings(model, class_prompts, device=DEVICE)\n",
    "except NameError:\n",
    "    # Fallback if utility function is not available\n",
    "    with torch.no_grad():\n",
    "        text_embeddings = {}\n",
    "        for cls, prompts in class_prompts.items():\n",
    "            embeddings = []\n",
    "            for prompt in prompts:\n",
    "                text = open_clip.tokenize([prompt]).to(DEVICE)\n",
    "                embeddings.append(model.encode_text(text))\n",
    "            text_embeddings[cls] = torch.mean(torch.cat(embeddings), dim=0, keepdim=True)\n",
    "            \n",
    "print(f\"Generated text embeddings for {len(text_embeddings)} classes\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Data Preparation\n",
    "\n",
    "Prepare the training data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Prepare training data\n",
    "train_images = [DATA_DIR / \"train\" / img_id if DATA_DIR.exists() else Path(\"/kaggle/input/soil-classification/soil_classification-2025/train\")/img_id \n",
    "               for img_id in train_df.image_id]\n",
    "\n",
    "# Use utility function if available, otherwise use inline code\n",
    "try:\n",
    "    X_train = get_image_embeddings(model, preprocess, train_images, batch_size=BATCH_SIZE, device=DEVICE)\n",
    "except NameError:\n",
    "    # Fallback if utility function is not available\n",
    "    def get_image_embeddings_inline(image_paths):\n",
    "        \"\"\"Batch processing to prevent OOM errors\"\"\"\n",
    "        embeddings = []\n",
    "        for i in range(0, len(image_paths), BATCH_SIZE):\n",
    "            batch_paths = image_paths[i:i+BATCH_SIZE]\n",
    "            batch = torch.stack([preprocess(Image.open(p).convert(\"RGB\")) for p in batch_paths])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                batch = batch.to(DEVICE)\n",
    "                batch_emb = model.encode_image(batch)\n",
    "                embeddings.append(batch_emb.cpu().numpy())\n",
    "            \n",
    "            # Explicit memory cleanup\n",
    "            del batch, batch_emb\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        return np.concatenate(embeddings)\n",
    "    \n",
    "    X_train = get_image_embeddings_inline(train_images)\n",
    "\n",
    "y_train = train_df.soil_type.map({cls:i for i, cls in enumerate(CLASSES)}).values\n",
    "\n",
    "print(f\"Prepared {len(X_train)} training samples with shape {X_train.shape}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Training\n",
    "\n",
    "Train a logistic regression classifier on the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Train classifier\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    C=0.1,\n",
    "    penalty=\"l2\",\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train_split, y_train_split)\n",
    "val_accuracy = clf.score(X_val_split, y_val_split)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2%}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Hybrid Prediction Function\n",
    "\n",
    "Define a function that combines logistic regression and zero-shot classification for improved predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Hybrid prediction function\n",
    "# Use utility function if available, otherwise use inline code\n",
    "if 'predict_image' not in globals():\n",
    "    def predict_image_inline(image_path):\n",
    "        \"\"\"Predict soil class for a single image using hybrid approach\"\"\"\n",
    "        # Get embeddings for logistic regression\n",
    "        if 'get_image_embeddings' in globals():\n",
    "            img_emb = get_image_embeddings(model, preprocess, [image_path], batch_size=1, device=DEVICE)\n",
    "        else:\n",
    "            img_emb = get_image_embeddings_inline([image_path])\n",
    "            \n",
    "        probe_pred = clf.predict_proba(img_emb)\n",
    "        \n",
    "        # Get embeddings for zero-shot classification\n",
    "        image = preprocess(Image.open(image_path).convert(\"RGB\")).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            zero_shot_probs = []\n",
    "            for cls in CLASSES:\n",
    "                text_features = text_embeddings[cls].to(DEVICE)\n",
    "                text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "                zero_shot_probs.append((image_features @ text_features.T).item())\n",
    "            zero_shot_probs = torch.softmax(torch.tensor(zero_shot_probs), dim=0).numpy()\n",
    "        \n",
    "        # Weighted ensemble (70% logistic regression, 30% zero-shot)\n",
    "        combined_probs = 0.7*probe_pred + 0.3*zero_shot_probs\n",
    "        return CLASSES[np.argmax(combined_probs)]\n",
    "    \n",
    "    # Use the inline function if the utility function is not available\n",
    "    if 'predict_image' not in globals():\n",
    "        predict_image = predict_image_inline\n",
    "\n",
    "print(\"Hybrid prediction function ready\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Set Prediction\n",
    "\n",
    "Generate predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Generate predictions for test set\n",
    "print(f\"Generating predictions for {len(test_df)} test images...\")\n",
    "test_images = [DATA_DIR / \"test\" / img_id if DATA_DIR.exists() else Path(\"/kaggle/input/soil-classification/soil_classification-2025/test\")/img_id \n",
    "              for img_id in test_df.image_id]\n",
    "\n",
    "# Use batch prediction if available, otherwise predict one by one\n",
    "if 'batch_predict' in globals():\n",
    "    predictions = batch_predict(test_images, model, preprocess, clf, text_embeddings, CLASSES, device=DEVICE, batch_size=BATCH_SIZE)\n",
    "else:\n",
    "    predictions = [predict_image(img_path) for img_path in test_images]\n",
    "\n",
    "print(f\"Predictions complete for {len(predictions)} images\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Create Submission\n",
    "\n",
    "Create a submission file with the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Create submission file\n",
    "output_file = \"submission.csv\"\n",
    "\n",
    "# Use utility function if available, otherwise use inline code\n",
    "if 'create_submission' in globals():\n",
    "    submission_path = create_submission(test_df, predictions, output_file)\n",
    "else:\n",
    "    test_df[\"soil_type\"] = predictions\n",
    "    test_df.to_csv(output_file, index=False)\n",
    "    submission_path = output_file\n",
    "    \n",
    "    # Print prediction distribution\n",
    "    print(f\"Prediction distribution:\\n{test_df['soil_type'].value_counts()}\")\n",
    "\n",
    "print(f\"\\nSubmission file created at: {submission_path}\")\n",
    "display(test_df.head(10))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "Summarize the inference process and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "source": [
    "print(\"Inference Summary:\")\n",
    "print(f\"- Model: {MODEL_NAME} with {PRETRAINED} weights\")\n",
    "print(f\"- Hybrid approach: 70% Logistic Regression, 30% Zero-Shot Classification\")\n",
    "print(f\"- Test samples: {len(test_df)}\")\n",
    "print(f\"- Validation accuracy: {val_accuracy:.2%}\")\n",
    "print(f\"- Classes: {CLASSES}\")\n",
    "print(f\"- Submission file: {submission_path}\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
